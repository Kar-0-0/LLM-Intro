{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = {i:s for s, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "N = torch.zeros(27, 27, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . e\n",
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n",
      "a . .\n",
      ". . o\n",
      ". o l\n",
      "o l i\n",
      "l i v\n",
      "i v i\n",
      "v i a\n",
      "i a .\n",
      "a . .\n",
      ". . a\n",
      ". a v\n",
      "a v a\n",
      "v a .\n",
      "a . .\n"
     ]
    }
   ],
   "source": [
    "for w in words[:3]:\n",
    "    w = '.' + '.' + w + '.' + '.'\n",
    "    for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
    "        print(ch1, ch2, ch3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 4.4100e+03, 1.3060e+03,  ..., 1.3400e+02,\n",
       "          5.3500e+02, 9.2900e+02],\n",
       "         [0.0000e+00, 2.0700e+02, 1.9000e+02,  ..., 2.7000e+01,\n",
       "          1.7300e+02, 1.5200e+02],\n",
       "         [0.0000e+00, 1.6900e+02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          4.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 5.7000e+01, 0.0000e+00,  ..., 1.0000e+00,\n",
       "          1.7000e+01, 1.1000e+01],\n",
       "         [0.0000e+00, 2.4600e+02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.0000e+00],\n",
       "         [0.0000e+00, 4.5600e+02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          9.1000e+01, 1.0000e+00]],\n",
       "\n",
       "        [[6.6400e+03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.0000e+01, 0.0000e+00, 5.0000e+00,  ..., 0.0000e+00,\n",
       "          2.0000e+01, 1.1000e+01],\n",
       "         [3.6000e+01, 2.8000e+01, 2.0000e+01,  ..., 0.0000e+00,\n",
       "          1.2000e+01, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.1000e+01, 5.0000e+00, 0.0000e+00,  ..., 1.7000e+01,\n",
       "          6.0000e+00, 3.0000e+00],\n",
       "         [1.6300e+02, 3.8900e+02, 1.3000e+01,  ..., 0.0000e+00,\n",
       "          1.6000e+01, 4.0000e+01],\n",
       "         [3.8000e+01, 1.2300e+02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.2000e+01, 2.2000e+01]],\n",
       "\n",
       "        [[1.1400e+02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.6000e+01, 5.0000e+00, 5.0000e+00,  ..., 4.0000e+00,\n",
       "          3.1000e+01, 4.0000e+00],\n",
       "         [1.0000e+00, 8.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          9.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.5000e+01, 4.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.6400e+02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+01, 0.0000e+00, 2.0000e+00,  ..., 0.0000e+00,\n",
       "          1.0000e+01, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.8000e+01, 3.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.0000e+00, 0.0000e+00],\n",
       "         [5.0000e+00, 4.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.6000e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[2.0070e+03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [7.1600e+02, 4.6000e+01, 1.0000e+01,  ..., 3.0000e+00,\n",
       "          6.0000e+00, 2.1000e+01],\n",
       "         [2.0000e+00, 2.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [2.3000e+01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 1.8000e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.0000e+00, 2.7000e+01, 0.0000e+00,  ..., 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.6000e+02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.8000e+01, 1.4000e+01, 4.0000e+01,  ..., 3.0000e+00,\n",
       "          9.7000e+01, 3.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.4000e+01, 2.7000e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [4.0000e+00, 1.3000e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in words:\n",
    "    w = '.' + '.' + w + '.' + '.'\n",
    "    for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        N[ix1, ix2, ix3] += 1\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 27, 27, 27\n",
    "# 27, 27,  1\n",
    "\n",
    "P = (N+1).float()\n",
    "P = P / P.sum(2, keepdim=True) \n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aquftoodiv.',\n",
       " 'bra.',\n",
       " 'kah.',\n",
       " 'peia.',\n",
       " 'mi.',\n",
       " 'evyonn.',\n",
       " 'gion.',\n",
       " 'aarichandrrajayessia.',\n",
       " 'barah.',\n",
       " 'achadellinal.',\n",
       " 'ariyah.',\n",
       " 'na.',\n",
       " 'mely.',\n",
       " 'na.',\n",
       " 'cat.',\n",
       " 'jaz.',\n",
       " 'aellang.',\n",
       " 'rana.',\n",
       " 'ais.',\n",
       " 'mus.',\n",
       " 'an.',\n",
       " 'an.',\n",
       " 'shi.',\n",
       " 'aleannaleigh.',\n",
       " 'deonzarrezmarlymah.',\n",
       " 'par.',\n",
       " 'da.',\n",
       " 'amer.',\n",
       " 'jah.',\n",
       " 'tabbtqi.',\n",
       " 'de.',\n",
       " 'zynniya.',\n",
       " 'aitcft.',\n",
       " 'aullen.',\n",
       " 'az.',\n",
       " 'del.',\n",
       " 'addhier.',\n",
       " 'do.',\n",
       " 'daston.',\n",
       " 'leilli.',\n",
       " 'edhylomatimee.',\n",
       " 'aellynoveecinedlwceliya.',\n",
       " 'salor.',\n",
       " 'gyn.',\n",
       " 'chazaffbduleinea.',\n",
       " 'bettyselah.',\n",
       " 'dya.',\n",
       " 'gen.',\n",
       " 'shiyock.',\n",
       " 'janiyah.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = \"\"\n",
    "ix = (0, 0)\n",
    "names = []\n",
    "\n",
    "for i in range(50):\n",
    "    while True:\n",
    "        ix = torch.multinomial(P[ix], num_samples=1, replacement=True)\n",
    "        curr_let = itos[ix.item()]\n",
    "        res += curr_let\n",
    "\n",
    "        if curr_let == '.':\n",
    "            break\n",
    "\n",
    "        if len(res) >= 2:\n",
    "            ix = (stoi[res[len(res) - 2]], stoi[res[len(res)-1]])\n",
    "        else:\n",
    "            ix = (0, stoi[res])\n",
    "    names.append(res)\n",
    "    res = \"\"\n",
    "    ix = (0, 0)\n",
    "names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.9420\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0\n",
    "n = 0\n",
    "for w in words:\n",
    "    w = '.' + '.' + w + '.' + '.'\n",
    "    for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        log_prob = torch.log(prob)\n",
    "        log_likelihood += log_prob\n",
    "        n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "nll /= n\n",
    "print(f\"Loss: {nll.item(): .4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Two: Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "itos = {i+1:s for i, s in enumerate(chars)}\n",
    "itos[0] = \".\"\n",
    "stoi = {s:i for i, s in itos.items()}\n",
    "\n",
    "stoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multi_hot(tuples, num_classes):\n",
    "    multi_hot_matrix = torch.zeros((len(tuples), num_classes))\n",
    "\n",
    "    for i, indices in enumerate(tuples):\n",
    "        multi_hot_matrix[i, indices] = 1  \n",
    "\n",
    "    return multi_hot_matrix\n",
    "\n",
    "multi_hot([(1, 2), (3, 4)], num_classes=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 5)]\n",
      "[5, 13]\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], [] # (., .) --> (e)\n",
    "for w in words:\n",
    "    w = \".\" + \".\" + w + \".\" + \".\"\n",
    "    for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(ix3)\n",
    "\n",
    "print(xs[:2])\n",
    "print(ys[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc = multi_hot(xs, num_classes=27)\n",
    "W = torch.randn((27, 27), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0742, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = Xenc @ W\n",
    "counts = logits.exp()\n",
    "p = counts / counts.sum(1, keepdim=True)\n",
    "loss = -p[torch.arange(p.shape[0]), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3777365684509277\n",
      "2.377725839614868\n",
      "2.377715826034546\n",
      "2.3777050971984863\n",
      "2.377695083618164\n",
      "2.3776845932006836\n",
      "2.3776745796203613\n",
      "2.377664566040039\n",
      "2.3776543140411377\n",
      "2.3776440620422363\n",
      "2.377634048461914\n",
      "2.377624273300171\n",
      "2.3776140213012695\n",
      "2.377603769302368\n",
      "2.377593994140625\n",
      "2.3775839805603027\n",
      "2.3775742053985596\n",
      "2.3775644302368164\n",
      "2.377554416656494\n",
      "2.37754487991333\n",
      "2.377535104751587\n",
      "2.3775253295898438\n",
      "2.3775157928466797\n",
      "2.3775062561035156\n",
      "2.3774964809417725\n",
      "2.3774867057800293\n",
      "2.3774776458740234\n",
      "2.3774681091308594\n",
      "2.377458333969116\n",
      "2.3774490356445312\n",
      "2.3774397373199463\n",
      "2.377429962158203\n",
      "2.377420663833618\n",
      "2.377411365509033\n",
      "2.3774023056030273\n",
      "2.3773930072784424\n",
      "2.3773839473724365\n",
      "2.3773744106292725\n",
      "2.3773655891418457\n",
      "2.3773562908172607\n",
      "2.377347469329834\n",
      "2.377338171005249\n",
      "2.377328872680664\n",
      "2.3773200511932373\n",
      "2.3773112297058105\n",
      "2.3773021697998047\n",
      "2.377293109893799\n",
      "2.377284526824951\n",
      "2.3772759437561035\n",
      "2.3772664070129395\n",
      "2.3772575855255127\n",
      "2.377249240875244\n",
      "2.3772401809692383\n",
      "2.3772315979003906\n",
      "2.377222776412964\n",
      "2.377214193344116\n",
      "2.3772053718566895\n",
      "2.3771965503692627\n",
      "2.377188205718994\n",
      "2.3771796226501465\n",
      "2.3771708011627197\n",
      "2.377162456512451\n",
      "2.3771541118621826\n",
      "2.377145528793335\n",
      "2.3771371841430664\n",
      "2.3771286010742188\n",
      "2.3771204948425293\n",
      "2.3771119117736816\n",
      "2.377103805541992\n",
      "2.3770954608917236\n",
      "2.377087354660034\n",
      "2.3770787715911865\n",
      "2.377070426940918\n",
      "2.3770625591278076\n",
      "2.37705397605896\n",
      "2.3770461082458496\n",
      "2.377037763595581\n",
      "2.3770296573638916\n",
      "2.3770217895507812\n",
      "2.377013683319092\n",
      "2.3770055770874023\n",
      "2.376997709274292\n",
      "2.3769896030426025\n",
      "2.376981496810913\n",
      "2.3769733905792236\n",
      "2.3769657611846924\n",
      "2.376957893371582\n",
      "2.3769497871398926\n",
      "2.3769421577453613\n",
      "2.376934289932251\n",
      "2.3769266605377197\n",
      "2.3769187927246094\n",
      "2.37691068649292\n",
      "2.3769030570983887\n",
      "2.3768954277038574\n",
      "2.376887559890747\n",
      "2.376879930496216\n",
      "2.3768725395202637\n",
      "2.3768649101257324\n",
      "2.376857042312622\n"
     ]
    }
   ],
   "source": [
    "Xenc = multi_hot(xs, num_classes=27)\n",
    "\n",
    "for i in range(100):\n",
    "    out = Xenc @ W\n",
    "    logits = out.exp()\n",
    "    p = logits / logits.sum(1, keepdim=True)\n",
    "    loss = -p[torch.arange(p.shape[0]), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      "o.\n",
      ".\n",
      "e.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "prob_dist must be 1 or 2 dim",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     ix \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     cur_let \u001b[38;5;241m=\u001b[39m itos[ix\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m      7\u001b[0m     res \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cur_let\n",
      "\u001b[1;31mRuntimeError\u001b[0m: prob_dist must be 1 or 2 dim"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ix = 0\n",
    "    res = \"\"\n",
    "    while True:\n",
    "        ix = torch.multinomial(p[ix], num_samples=1, replacement=True)\n",
    "        cur_let = itos[ix.item()]\n",
    "        res += cur_let\n",
    "        if ix == 0:\n",
    "            break \n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
